{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning course for astro PhD students\n",
    "\n",
    "##### Alexandre Boucaud (APC) & Marc Huertas-Company (LERMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Data](#Data)\n",
    "3. [Workflow](#Workflow)\n",
    "4. [Evaluation](#Detection-evaluation)\n",
    "5. [Local testing/exploration](#Local-testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In astronomical images, the projection effects may cause two or more galaxies to overlap. When they are barely indistinguishable from one another, they are referred to as _blended_ and this can bias astrophysical estimators such as the morphology of galaxies or the shear (weak gravitational lensing distortion).  \n",
    "As the sensitivity of imaging devices grows, a high fraction of galaxies appear _blended_ in the images, which is a known and important issue for current and upcoming galaxy surveys.  \n",
    "\n",
    "In order not to discard such a wealth of information, it is key to develop methods to enable astronomers to alleviate such effect.\n",
    "We can foresee some features that would help, in which machine learning could provide a solution:\n",
    "- classify an image as containing isolated/blended objects  \n",
    "  ___binary classification___\n",
    "- count the number of blended sources in a blended image  \n",
    "  ___regression / object detection___\n",
    "- find the contours of each object  \n",
    "  ___object detection/segmentation___\n",
    "- ...\n",
    "\n",
    "In this exercice, we will approach the third item, the detection of contours, but in a constrained way : the images will only contain **two galaxies** and the goal will be to find the **contours of the central galaxy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Install the dltools lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/aboucaud/deeplearning4astro_labs_2019\n",
    "!cd deeplearning4astro_labs_2019/labs/deblending\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_blends_mini.npy        train_blends_mini.npy\r\n",
      "test_target_img_mini.npy    train_target_img_mini.npy\r\n",
      "test_target_masks_mini.npy  train_target_masks_mini.npy\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "URL = \"https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud\"\n",
    "FOLDER = \"ed127\"\n",
    "FILES = [\n",
    "    \"test_blends_mini.npy\",\n",
    "    \"test_target_img_mini.npy\",\n",
    "    \"test_target_masks_mini.npy\",\n",
    "    \"train_blends_mini.npy\",\n",
    "    \"train_target_img_mini.npy\",\n",
    "    \"train_target_masks_mini.npy\",\n",
    "\n",
    "]\n",
    "BIG_FILES = [\n",
    "    \"masks.tar.gz\",\n",
    "    \"single_imgs.tar.gz\",\n",
    "    \"blends.tar.gz\",\n",
    "]\n",
    "\n",
    "def main(output_dir, delete=False, full=False):\n",
    "    if full:\n",
    "        files = BIG_FILES\n",
    "    else:\n",
    "        files = FILES\n",
    "\n",
    "    urls = [\n",
    "        f\"{URL}/{FOLDER}/{filename}\"\n",
    "        for filename in files\n",
    "    ]\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Creating directory {output_dir}\")\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    for url, filename in zip(urls, files):\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"{filename} already downloaded.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading from {url} ...\")\n",
    "        urlretrieve(url, filename=output_file)\n",
    "        print(f\"=> File saved as {output_file}\")\n",
    "\n",
    "        if filename.endswith(\"tar.gz\"):\n",
    "            print(\"Extracting tarball..\")\n",
    "            with tarfile.open(output_file, \"r:gz\") as f:\n",
    "                f.extractall(output_dir)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            if delete:\n",
    "                os.remove(output_file)\n",
    "                print(f\"=> File {output_file} removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(output_dir='data', full=False)                \n",
    "# main(output_dir='data', delete=True, full=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dltools.detector import ObjectDetector\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\"\n",
    "suffix = \"_mini\"\n",
    "# suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(datadir, f\"train_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_train = np.load(os.path.join(datadir, f\"train_target_masks{suffix}.npy\"), mmap_mode='r')\n",
    "\n",
    "X_test = np.load(os.path.join(datadir, f\"test_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_test = np.load(os.path.join(datadir, f\"test_target_masks{suffix}.npy\"), mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE\n",
    "# ===========\n",
    "filename = \"alex_testfcnn.py\"\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    UpSampling2D,\n",
    ")\n",
    "from keras.layers.noise import GaussianNoise\n",
    "\n",
    "\n",
    "def model():\n",
    "    input_shape = (128, 128, 1)\n",
    "    output_channels = 1\n",
    "    depth = 16\n",
    "    n_layers = 6\n",
    "    conv_size0 = (3, 3)\n",
    "    conv_size = (3, 3)\n",
    "    last_conv_size = (3, 3)\n",
    "    activation = \"relu\"\n",
    "    last_activation = \"sigmoid\"\n",
    "    dropout_rate = 0\n",
    "    sigma_noise = 0.01\n",
    "    initialization = \"he_normal\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            depth,\n",
    "            conv_size0,\n",
    "            input_shape=input_shape,\n",
    "            activation=activation,\n",
    "            padding=\"same\",\n",
    "            name=\"conv0\",\n",
    "            kernel_initializer=initialization,\n",
    "        )\n",
    "    )\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for layer_n in range(1, n_layers):\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                depth,\n",
    "                conv_size,\n",
    "                activation=activation,\n",
    "                padding=\"same\",\n",
    "                name=\"conv{}\".format(layer_n),\n",
    "                kernel_initializer=initialization,\n",
    "            )\n",
    "        )\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if sigma_noise > 0:\n",
    "        model.add(GaussianNoise(sigma_noise))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            output_channels,\n",
    "            last_conv_size,\n",
    "            activation=last_activation,\n",
    "            padding=\"same\",\n",
    "            name=\"last\",\n",
    "            kernel_initializer=initialization,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modulename = os.path.splitext(filename)[0]\n",
    "\n",
    "binome, submission = modulename.split('_')\n",
    "\n",
    "os.makedirs(modulename)\n",
    "history_file = os.path.join(modulename, f\"{modulename}_history.png\")\n",
    "sample_file = os.path.join(modulename, f\"{modulename}_image_sample.png\")\n",
    "\n",
    "print(f\"\\nTraining submission {submission} by {binome}...\\n\")\n",
    "\n",
    "obj = ObjectDetector(model(), batch_size=16, epoch=10, model_check_point=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training...\")\n",
    "history = obj.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "score = obj.predict_score(X_test.squeeze(), Y_test)\n",
    "\n",
    "print(f\"Score: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
