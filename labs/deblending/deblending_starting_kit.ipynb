{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning course for astro PhD students\n",
        "\n##### Alexandre Boucaud (APC) & Marc Huertas-Company (LERMA)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Introduction](#Introduction)\n",
        "2. [Data](#Data)\n",
        "3. [Workflow](#Workflow)\n",
        "4. [Evaluation](#Detection-evaluation)\n",
        "5. [Local testing/exploration](#Local-testing)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In astronomical images, the projection effects may cause two or more galaxies to overlap. When they are barely indistinguishable from one another, they are referred to as _blended_ and this can bias astrophysical estimators such as the morphology of galaxies or the shear (weak gravitational lensing distortion).  \n",
        "As the sensitivity of imaging devices grows, a high fraction of galaxies appear _blended_ in the images, which is a known and important issue for current and upcoming galaxy surveys.  \n",
        "\n",
        "In order not to discard such a wealth of information, it is key to develop methods to enable astronomers to alleviate such effect.\n",
        "We can foresee some features that would help, in which machine learning could provide a solution:\n",
        "- classify an image as containing isolated/blended objects  \n",
        "  ___binary classification___\n",
        "- count the number of blended sources in a blended image  \n",
        "  ___regression / object detection___\n",
        "- find the contours of each object  \n",
        "  ___object detection/segmentation___\n",
        "- ...\n",
        "\nIn this exercice, we will approach the third item, the detection of contours, but in a constrained way : the images will only contain **two galaxies** and the goal will be to find the **contours of the central galaxy**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\nInstall the dltools lib"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/aboucaud/deeplearning4astro_tools"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\nDownload the data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "URL = \"https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud\"\n",
        "FOLDER = \"ed127\"\n",
        "FILES = [\n",
        "    \"test_blends_mini.npy\",\n",
        "    \"test_target_img_mini.npy\",\n",
        "    \"test_target_masks_mini.npy\",\n",
        "    \"train_blends_mini.npy\",\n",
        "    \"train_target_img_mini.npy\",\n",
        "    \"train_target_masks_mini.npy\",\n",
        "\n",
        "]\n",
        "BIG_FILES = [\n",
        "    \"masks.tar.gz\",\n",
        "    \"single_imgs.tar.gz\",\n",
        "    \"blends.tar.gz\",\n",
        "]\n",
        "\n",
        "def main(output_dir, delete=False, full=False):\n",
        "    if full:\n",
        "        files = BIG_FILES\n",
        "    else:\n",
        "        files = FILES\n",
        "\n",
        "    urls = [\n",
        "        f\"{URL}/{FOLDER}/{filename}\"\n",
        "        for filename in files\n",
        "    ]\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"Creating directory {output_dir}\")\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    for url, filename in zip(urls, files):\n",
        "        output_file = os.path.join(output_dir, filename)\n",
        "\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"{filename} already downloaded.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading from {url} ...\")\n",
        "        urlretrieve(url, filename=output_file)\n",
        "        print(f\"=> File saved as {output_file}\")\n",
        "\n",
        "        if filename.endswith(\"tar.gz\"):\n",
        "            print(\"Extracting tarball..\")\n",
        "            with tarfile.open(output_file, \"r:gz\") as f:\n",
        "                f.extractall(output_dir)\n",
        "            print(\"Done.\")\n",
        "\n",
        "            if delete:\n",
        "                os.remove(output_file)\n",
        "                print(f\"=> File {output_file} removed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_blends_mini.npy        train_blends_mini.npy\r\n",
            "test_target_img_mini.npy    train_target_img_mini.npy\r\n",
            "test_target_masks_mini.npy  train_target_masks_mini.npy\r\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "main(output_dir='data', full=False)                \n",
        "# main(output_dir='data', delete=True, full=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dltools.detector import ObjectDetector\n",
        "%matplotlib inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "datadir = \"data\"\n",
        "suffix = \"_mini\"\n",
        "# suffix = \"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load(os.path.join(datadir, f\"train_blends{suffix}.npy\"), mmap_mode='r')\n",
        "Y_train = np.load(os.path.join(datadir, f\"train_target_masks{suffix}.npy\"), mmap_mode='r')\n",
        "\n",
        "X_test = np.load(os.path.join(datadir, f\"test_blends{suffix}.npy\"), mmap_mode='r')\n",
        "Y_test = np.load(os.path.join(datadir, f\"test_target_masks{suffix}.npy\"), mmap_mode='r')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE HERE\n",
        "# ===========\n",
        "filename = \"alex_testfcnn.py\"\n",
        "\n",
        "modulename = os.path.splitext(filename)[0]\n",
        "binome, submission = modulename.split('_')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE HERE\n",
        "# ===========\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import (\n",
        "    Conv2D,\n",
        "    Dropout,\n",
        "    Input,\n",
        "    MaxPooling2D,\n",
        "    concatenate,\n",
        "    Conv2DTranspose,\n",
        "    UpSampling2D,\n",
        ")\n",
        "from keras.layers.noise import GaussianNoise\n",
        "\n\n",
        "def model():\n",
        "    input_shape = (128, 128, 1)\n",
        "    output_channels = 1\n",
        "    depth = 16\n",
        "    n_layers = 6\n",
        "    conv_size0 = (3, 3)\n",
        "    conv_size = (3, 3)\n",
        "    last_conv_size = (3, 3)\n",
        "    activation = \"relu\"\n",
        "    last_activation = \"sigmoid\"\n",
        "    dropout_rate = 0\n",
        "    sigma_noise = 0.01\n",
        "    initialization = \"he_normal\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            depth,\n",
        "            conv_size0,\n",
        "            input_shape=input_shape,\n",
        "            activation=activation,\n",
        "            padding=\"same\",\n",
        "            name=\"conv0\",\n",
        "            kernel_initializer=initialization,\n",
        "        )\n",
        "    )\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for layer_n in range(1, n_layers):\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                depth,\n",
        "                conv_size,\n",
        "                activation=activation,\n",
        "                padding=\"same\",\n",
        "                name=\"conv{}\".format(layer_n),\n",
        "                kernel_initializer=initialization,\n",
        "            )\n",
        "        )\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "    if sigma_noise > 0:\n",
        "        model.add(GaussianNoise(sigma_noise))\n",
        "\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            output_channels,\n",
        "            last_conv_size,\n",
        "            activation=last_activation,\n",
        "            padding=\"same\",\n",
        "            name=\"last\",\n",
        "            kernel_initializer=initialization,\n",
        "        )\n",
        "    )\n",
        "\n    return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# POSSIBLY CHANGE HERE THE NUMBER OF EPOCHS OR THE BATCH SIZE\n",
        "obj = ObjectDetector(model(), batch_size=16, epoch=10, model_check_point=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTraining submission {submission} by {binome}...\\n\")\n",
        "history = obj.fit(X_train, Y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTesting submission {submission} by {binome}...\\n\")\n",
        "score = obj.predict_score(X_test.squeeze(), Y_test)\n",
        "\nprint(f\"Score: {score:.2f}\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_random_results(X_test, y_test):\n",
        "    n_gal = 5\n",
        "    idx = np.random.randint(0, len(y_test), size=n_gal)\n",
        "    X = X_test[idx]\n",
        "    if X.ndim == 3:\n",
        "        X = np.expand_dims(X, -1)\n",
        "    y_true = y_test[idx]\n",
        "    y_pred = obj.model_.predict(X)\n",
        "\n",
        "    titles = [\n",
        "        'blend',\n",
        "        'true segmentation',\n",
        "        'output',\n",
        "        'output thresholded',\n",
        "    ]\n",
        "    fig_size = (10, 12)\n",
        "    fig, ax = plt.subplots(nrows=n_gal, ncols=4, figsize=fig_size)\n",
        "    for i in range(n_gal):\n",
        "        img = np.squeeze(X[i])\n",
        "        yt = np.squeeze(y_true[i])\n",
        "        yp = np.squeeze(y_pred[i])\n",
        "        ax[i, 0].imshow(img)\n",
        "        ax[i, 1].imshow(yt)\n",
        "        ax[i, 2].imshow(yp)\n",
        "        ax[i, 3].imshow(yp.round())\n",
        "        if i == 0:\n",
        "            for idx, a in enumerate(ax[i]):\n",
        "                a.set_title(titles[idx])\n",
        "        for a in ax[i]:\n",
        "            a.set_axis_off()\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.semilogy(history.epoch, history.history['loss'], label='loss')\n",
        "    plt.semilogy(history.epoch, history.history['val_loss'], label='val_loss')\n",
        "    plt.title('Training performance')\n",
        "    plt.xlim(1, None)\n",
        "    plt.legend()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot some examples"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_results(X_test, Y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the history"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}